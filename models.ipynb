{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings \n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier as model\n",
    "import pickle\n",
    "import math\n",
    "import itertools\n",
    "import joblib\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import RandomForestClassifier as RF\n",
    "from xgboost import XGBClassifier as XGB\n",
    "from numpy import hstack\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "import sklearn.metrics as metrics\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_TRAIN=pd.read_csv('../../New Folder/final.csv').drop('y',axis=1)\n",
    "Y_TRAIN=pd.read_csv('../../New Folder/final.csv')['y']\n",
    "\n",
    "X_VALIDATION=pd.read_csv('../../New Folder/val.csv').drop('y',axis=1)\n",
    "Y_VALIDATION=pd.read_csv('../../New Folder/val.csv')['y']\n",
    "\n",
    "\n",
    "X_TEST=pd.read_csv('../../New Folder/test.csv').drop('y',axis=1)\n",
    "Y_TEST=pd.read_csv('../../New Folder/test.csv')['y']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, (ax1, ax2) = plt.subplots(2, 1, figsize=(24,20))\n",
    "\n",
    "# Entire DataFrame\n",
    "corr = X_TRAIN.corr()\n",
    "sns.heatmap(corr, cmap='coolwarm_r', annot_kws={'size':20}, ax=ax1)\n",
    "ax1.set_title(\"Imbalanced Correlation Matrix Train)\", fontsize=14)\n",
    "\n",
    "\n",
    "sub_sample_corr = X_VALIDATION.corr()\n",
    "sns.heatmap(sub_sample_corr, cmap='coolwarm_r', annot_kws={'size':20}, ax=ax2)\n",
    "ax2.set_title(' Correlation Matrix Val', fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_TRAIN.shape,Y_TRAIN.shape)\n",
    "print(X_VALIDATION.shape,Y_VALIDATION.shape)\n",
    "print(X_TEST.shape,Y_TEST.shape)\n",
    "\n",
    "min_max_scaler = MinMaxScaler().fit(X_TRAIN) # Fit On Training Data\n",
    "X_TRAIN = min_max_scaler.transform(X_TRAIN) # Transform On Training Data\n",
    "X_VALIDATION= min_max_scaler.transform(X_VALIDATION) # Transform On Validation Data\n",
    "X_TEST= min_max_scaler.transform(X_TEST) # Transform On Testing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1_XGBOOST = joblib.load('model_1XGB.pkl')\n",
    "model_1_RF = joblib.load('model_1RF.pkl')\n",
    "model_1_SVM = joblib.load('model_1SVM.pkl') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XGB_val=model_1_XGBOOST.predict(X_VALIDATION)\n",
    "RF_val=model_1_RF.predict(X_VALIDATION)\n",
    "SVM_val=model_1_SVM.predict(X_VALIDATION)\n",
    "XGB_test=model_1_XGBOOST.predict(X_TEST)\n",
    "RF_test=model_1_RF.predict(X_TEST)\n",
    "SVM_test=model_1_SVM.predict(X_TEST)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_classes(probability_array):\n",
    "    for i in range(len(probability_array)):\n",
    "        if (probability_array[i]>0.5):\n",
    "            probability_array[i]=1\n",
    "        else:\n",
    "            probability_array[i]=0\n",
    "    return (probability_array) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_check(AY_VALIDATE,AX_VALIDATE):\n",
    "\n",
    "    abc=confusion_matrix(AY_VALIDATE,AX_VALIDATE,normalize='true')\n",
    "\n",
    "    TN=abc[0][0]\n",
    "    FP=abc[0][1]\n",
    "    FN=abc[1][0]\n",
    "    TP=abc[1][1]\n",
    "\n",
    "    PS=FN+TP\n",
    "    NS=TN+FP\n",
    "    Accuracy           = ((TP+TN)/(PS+NS))*100\n",
    "    Sensitivity        = (TP/PS)*100\n",
    "    Precision          = (TP/(FP+TP))*100\n",
    "    F1                 = (2*Sensitivity*Precision)/(Sensitivity+Precision )\n",
    "    Speciﬁcity         = (TN/NS)*100\n",
    "    MCC                = (( (TP * TN) - (FP * FN )) /  math.sqrt (( TP + FP )*( TP + FN )*( TN + FP )*( TN + FN )))\n",
    "    print('Accuracy:' ,Accuracy)\n",
    "    print('Sensitivity:', Sensitivity)\n",
    "    print('Precision:' ,Precision)\n",
    "    print('Matthews',MCC)\n",
    "\n",
    "    cmap=plt.cm.Greens\n",
    "    title='Confusion matrix'\n",
    "    cm=abc\n",
    "    classes = ['No-Landslide', 'Landslide']\n",
    "    normalize=True\n",
    "\n",
    "    plt.figure(figsize = (10, 10))\n",
    "    plt.imshow(cm, cmap=cmap)\n",
    "    plt.title(title, size = 24)\n",
    "    plt.colorbar(aspect=4)\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45, size = 14)\n",
    "    plt.yticks(tick_marks, classes, size = 14)\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    # Label the plot\n",
    "    for i, j in itertools.product(range(cm.shape[0]),   range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt), \n",
    "             fontsize = 20,\n",
    "             horizontalalignment=\"center\",\n",
    "             color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "        \n",
    "    # plt.grid()\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label', size = 18)\n",
    "    plt.xlabel('Predicted label', size = 18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_check(Y_TEST,model_1_XGBOOST.predict(X_TEST))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_check(Y_VALIDATION,model_1_XGBOOST.predict(X_VALIDATION))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_check(Y_VALIDATION,model_1_RF.predict(X_VALIDATION))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_check(Y_TEST,model_1_SVM.predict(X_TEST))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "n_estimators = 1000\n",
    "max_features = 'sqrt'\n",
    "\n",
    "max_depth=11\n",
    "learning_rate=0.001\n",
    "kernel ='rbf'\n",
    "C = 1.0 # default=1.0\n",
    "\n",
    "\n",
    "def get_models():\n",
    "\tmodels = list()\n",
    "\tmodels.append(('RF', RF(n_estimators=n_estimators,max_features='sqrt',n_jobs=16)))\n",
    "\tmodels.append(('XGB',XGB(max_depth=max_depth,learning_rate=learning_rate,n_estimators=500,n_jobs=20)))\n",
    "\tmodels.append(('svm', SVC(kernel=kernel,C=C,probability=True)))\n",
    "\treturn models\n",
    "\n",
    "def fit_ensemble(models, X_train, X_val, y_train, y_val):\n",
    "\t# fit all models on the training set and predict on hold out set\n",
    "\tmeta_X = list()\n",
    "\tfor name, model in models:\n",
    "\t\t# fit in training set\n",
    "\t\tmodel.fit(X_train, y_train)\n",
    "\t\t# predict on hold out set\n",
    "\t\tyhat = model.predict(X_val)\n",
    "\t\t# reshape predictions into a matrix with one column\n",
    "\t\tyhat = yhat.reshape(len(yhat), 1)\n",
    "\t\t# store predictions as input for blending\n",
    "\t\tmeta_X.append(yhat)\n",
    "\t# create 2d array from predictions, each set is an input feature\n",
    "\tmeta_X = hstack(meta_X)\n",
    "\t# define blending model\n",
    "\tblender = LogisticRegression()\n",
    "\t# fit on predictions from base models\n",
    "\tblender.fit(meta_X, y_val)\n",
    "\treturn blender\n",
    "\n",
    "def predict_ensemble(models, blender, X_test):\n",
    "\t# make predictions with base models\n",
    "\tmeta_X = list()\n",
    "\tfor name, model in models:\n",
    "\t\t# predict with base model\n",
    "\t\tyhat = model.predict(X_test)\n",
    "\t\t# reshape predictions into a matrix with one column\n",
    "\t\tyhat = yhat.reshape(len(yhat), 1)\n",
    "\t\t# store prediction\n",
    "\t\tmeta_X.append(yhat)\n",
    "\t# create 2d array from predictions, each set is an input feature\n",
    "\tmeta_X = hstack(meta_X)\n",
    "\t# predict\n",
    "\treturn blender.predict_proba(meta_X)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_TRAIN, Y_TRAIN, test_size=0.33, random_state=1)\n",
    "\n",
    "models = get_models()\n",
    "# train the blending ensemble\n",
    "blender = fit_ensemble(models, X_train, X_val, y_train, y_val)\n",
    "# make predictions on test set\n",
    "yhat = predict_ensemble(models, blender, X_TEST)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clas=predict_classes(yhat[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_check(Y_TEST,clas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_val=predict_ensemble(models,blender,X_TEST)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def roc_curve(prob,y):\n",
    "    fpr, tpr, threshold = metrics.roc_curve(y,prob[:,1])\n",
    "    roc_auc = metrics.auc(fpr, tpr)\n",
    "    return(fpr,tpr,roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr1,tpr1,roc_auc1=roc_curve(model_1_RF.predict_proba(X_TEST),Y_TEST)\n",
    "fpr2,tpr2,roc_auc2=roc_curve(model_1_XGBOOST.predict_proba(X_TEST),Y_TEST)\n",
    "fpr3,tpr3,roc_auc3=roc_curve(model_1_SVM.predict_proba(X_TEST),Y_TEST)\n",
    "fpr4,tpr4,roc_auc4=roc_curve(ensemble_val.predict_proba(X_TEST),Y_TEST)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig =plt.figure(figsize=(15,10))\n",
    "ax=plt.axes()\n",
    "plt.title('AUC ROC curves',size=40)\n",
    "plt.plot(fpr1, tpr1, 'b', label = 'AUC SVM = %0.3f' % roc_auc1)\n",
    "plt.plot(fpr2, tpr2, 'r', label = 'AUC XGBOOST = %0.3f'% roc_auc2)\n",
    "plt.plot(fpr3, tpr3, 'g', label = 'AUC RF = %0.3f' % roc_auc3)\n",
    "plt.plot(fpr4, tpr4, 'g', label = 'AUC RF = %0.3f' % roc_auc4)\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate',size=20)\n",
    "plt.xlabel('False Positive Rate',size=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "feature_scores = model_1_RF.feature_importances_ \n",
    "index=[ 'NDVI', 'TWI', 'Downslope', 'Upslope', 'Curvature',\n",
    "       'Elevation', 'Precipitation', 'Slope', 'Clay', 'Sand', 'Silt', 'Lineament',\n",
    "       'Road', 'Rivers', 'Soil_depth', 'R_factor', 'Aspect'].sort_values(ascending=False)\n",
    "sns.barplot(x=feature_scores, y=feature_scores.index)\n",
    "# Add labels to the graph\n",
    "plt.xlabel('Feature Importance Score',size=20)\n",
    "plt.ylabel('Landslide Conditioning Factors',size=18)\n",
    "# Add title to the graph\n",
    "# Visualize the graph\n",
    "plt.savefig('./RF_imp.jpg',dpi=400)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "1.ipynb",
   "provenance": []
  },
  "interpreter": {
   "hash": "6425cd888af6a2f896432ef0d705523b9536cd7ba79c7f684761719aa77915d3"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('tensor': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
